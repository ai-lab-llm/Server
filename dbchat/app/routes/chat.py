from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from langgraph.errors import GraphRecursionError
from app.graph.workflow import run_graph
from app.utils.intent import classify_intent_llm, list_known_names
import asyncio, re

router = APIRouter()

class AskRequest(BaseModel):
    thread_id: str | None = None
    question: str
    options: dict = {}
    ui_context: dict = {}
    recursive_limit: int | None = None

def _strip_tag(text: str) -> str:
    if not isinstance(text, str):
        return text
    return re.sub(r'(?m)^\s*(Final:|Answer:)\s*', '', text).strip()

def _build_guide() -> str:
    names = list_known_names(limit=3)
    name_hint = (f" (ì˜ˆ: {', '.join(names)})" if names else "")
    return (
        "ì´ í™”ë©´ì—ì„œëŠ” ë³´í˜¸ëŒ€ìƒìì˜ ë°ì´í„° ì¡°ê±´ ê²€ìƒ‰ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
        "ëˆ„êµ¬ì˜ ì–´ë–¤ ì •ë³´ë¥¼ ì•Œê³ ì‹¶ìœ¼ì‹ ê°€ìš”? ğŸ˜Š\n"
    )


@router.post("/ask")
async def ask(req: AskRequest):
    q = (req.question or "").strip()
    if not q:
        return {"thread_id": req.thread_id or "temp",
                "message": {"role": "ai", "content": "ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."}}

    intent = classify_intent_llm(q)
    if intent != "db_query":
        guide = _build_guide()
        return {"thread_id": req.thread_id or "temp",
                "message": {"role": "ai", "content": guide}}

    limit = req.recursive_limit if req.recursive_limit is not None else req.options.get("recursive_limit", 30)
    if isinstance(limit, int):
        limit = max(15, min(limit, 100))

    try:
        state = run_graph(q, recursive_limit=limit)
    except GraphRecursionError as e:
        raise HTTPException(status_code=422, detail=str(e))

    messages = state.get("messages", [])
    final = answer = fallback = None
    for m in reversed(messages):
        c = getattr(m, "content", None)
        t = getattr(m, "type", None)
        if isinstance(c, str) and c.strip():
            if t == "ai" and c.startswith("Final:"):
                final = c; break
            if t == "ai" and c.startswith("Answer:") and answer is None:
                answer = c
            if fallback is None:
                fallback = c
    content = _strip_tag(final or answer or (fallback or "ì‘ë‹µ ì—†ìŒ"))

    return {"thread_id": req.thread_id or "temp",
            "message": {"role": "ai", "content": content}}


# /ask_stream : ìŠ¤íŠ¸ë¦¬ë°(ìœ ì‚¬-í† í°) 
def _chunk_text(s: str, *, size: int = 16):
    """ë¬¸ìì—´ì„ size í¬ê¸° ì¡°ê°ìœ¼ë¡œ ì˜ë¼ ìˆœì„œëŒ€ë¡œ ë°˜í™˜"""
    for i in range(0, len(s), size):
        yield s[i:i+size]

@router.post("/ask_stream")
async def ask_stream(req: AskRequest):
    q = (req.question or "").strip()

    async def _once(text: str):
        for part in _chunk_text(text, size=32):
            yield part
            await asyncio.sleep(0.008)

    # ë¹ˆ ì§ˆë¬¸
    if not q:
        return StreamingResponse(
            _once("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."),
            media_type="text/plain; charset=utf-8",
            headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},  # Nginx ë²„í¼ ë„ê¸°
        )

    # ì¸í…íŠ¸ í™•ì¸
    intent = classify_intent_llm(q)
    if intent != "db_query":
        guide = _build_guide()
        return StreamingResponse(
            _once(guide),
            media_type="text/plain; charset=utf-8",
            headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
        )

    # ê·¸ë˜í”„ ì‹¤í–‰
    limit = req.recursive_limit if req.recursive_limit is not None else req.options.get("recursive_limit", 30)
    if isinstance(limit, int):
        limit = max(15, min(limit, 100))

    async def generator():
        try:
            state = run_graph(q, recursive_limit=limit)
            messages = state.get("messages", [])
            final = answer = fallback = None
            for m in reversed(messages):
                c = getattr(m, "content", None)
                t = getattr(m, "type", None)
                if isinstance(c, str) and c.strip():
                    if t == "ai" and c.startswith("Final:"):
                        final = c; break
                    if t == "ai" and c.startswith("Answer:") and answer is None:
                        answer = c
                    if fallback is None:
                        fallback = c
            content = _strip_tag(final or answer or (fallback or "ì‘ë‹µ ì—†ìŒ"))

            # ë³¸ë¬¸ì„ ì˜ê²Œ ì˜ë¼ ì „ì†¡
            for part in _chunk_text(content, size=18):
                yield part
                await asyncio.sleep(0.008)

            # ë í‘œì‹œ
            yield "\n"
        except GraphRecursionError as e:
            yield f"[ì˜¤ë¥˜] {str(e)}\n"
        except Exception as e:
            yield f"[ì˜ˆì™¸] {repr(e)}\n"

    return StreamingResponse(
        generator(),
        media_type="text/plain; charset=utf-8",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},  # Nginx ë²„í¼ ë„ê¸°
    )


# ë””ë²„ê·¸ìš© ìŠ¤íŠ¸ë¦¼: íŒŒì´í”„ë¼ì¸ í™•ì¸ìš© 
@router.get("/_debug/stream")
async def debug_stream():
    async def gen():
        for i in range(1, 8):
            yield f"chunk-{i}\n"
            await asyncio.sleep(0.25)
    return StreamingResponse(
        gen(),
        media_type="text/plain; charset=utf-8",
        headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"},
    )